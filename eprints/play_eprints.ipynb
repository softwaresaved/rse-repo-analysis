{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with ePrints publications\n",
    "\n",
    "This notebook is a space for getting a feel for ePrints repositories, how best to request data, how to parse it and get the info that we want.\n",
    "It's also a useful space to debug snippets of code that throw errors in the main scripts."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filtering for Item Types *Articles* and *Research Reports or Papers*\n",
    "- XML output works for Southampton Uni (yay!)\n",
    "- based on Philly's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"eprints.soton.ac.uk\"\n",
    "date = \"2022-\"\n",
    "type = \"paper\"\n",
    "\n",
    "request = f\"https://{repo}/cgi/search/archive/advanced?screen=Search&\" \\\n",
    "            \"output=XML&\" \\\n",
    "            \"_action_export_redir=Export&\" \\\n",
    "            \"dataset=archive&\" \\\n",
    "            \"_action_search=Search&\" \\\n",
    "            \"documents_merge=ALL&\" \\\n",
    "            \"documents=&\" \\\n",
    "            \"eprintid=&\" \\\n",
    "            \"title_merge=ALL&\" \\\n",
    "            \"title=&\" \\\n",
    "            \"contributors_name_merge=ALL&\" \\\n",
    "            \"contributors_name=&\" \\\n",
    "            \"abstract_merge=ALL&\" \\\n",
    "            \"abstract=&\" \\\n",
    "            f\"date=&\" \\\n",
    "            \"keywords_merge=ALL&\" \\\n",
    "            \"keywords=&\" \\\n",
    "            \"divisions_merge=ANY&\" \\\n",
    "            f\"pres_type={type}&\" \\\n",
    "            \"refereed=EITHER&\" \\\n",
    "            \"publication%2Fseries_name_merge=ALL&\" \\\n",
    "            \"publication%2Fseries_name=&\" \\\n",
    "            \"documents.date_embargo=&\" \\\n",
    "            \"lastmod=&\" \\\n",
    "            \"pure_uuid=&\" \\\n",
    "            \"contributors_id=&\" \\\n",
    "            \"satisfyall=ALL&\" \\\n",
    "            \"order=contributors_name%2F-date%2Ftitle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://eprints.soton.ac.uk/cgi/search/archive/advanced?screen=Search&output=XML&_action_export_redir=Export&dataset=archive&_action_search=Search&documents_merge=ALL&documents=&eprintid=&title_merge=ALL&title=&contributors_name_merge=ALL&contributors_name=&abstract_merge=ALL&abstract=&date=&keywords_merge=ALL&keywords=&divisions_merge=ANY&pres_type=paper&refereed=EITHER&publication%2Fseries_name_merge=ALL&publication%2Fseries_name=&documents.date_embargo=&lastmod=&pure_uuid=&contributors_id=&satisfyall=ALL&order=contributors_name%2F-date%2Ftitle\n"
     ]
    }
   ],
   "source": [
    "print(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"export.xml\", \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the publications\n",
    "\n",
    "Useful links:\n",
    "- [Pubmed Parser](https://github.com/titipata/pubmed_parser)\n",
    "- [lxml](https://pypi.org/project/lxml/)\n",
    "- [short intro to lxml](https://realpython.com/python-xml-parser/#lxml-use-elementtree-on-steroids)\n",
    "- [lxml tutorial: parsing](https://lxml.de/tutorial.html)\n",
    "\n",
    "Problem: does not contain full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"export.xml\"\n",
    "with open(data, \"rb\") as f:\n",
    "    tree = etree.parse(f)\n",
    "root = tree.getroot()  # holds list of eprints, tagged <eprints>...</eprints>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eprints\n",
      "http://eprints.org/ep2/data/2.0\n"
     ]
    }
   ],
   "source": [
    "root_tag = etree.QName(root.tag)\n",
    "print(root_tag.localname)\n",
    "print(root_tag.namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27366\n"
     ]
    }
   ],
   "source": [
    "children = list(root)  # should be list of entries <eprint>;;;</eprint>\n",
    "print(len(children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_fields_content(element, field_name):\n",
    "    \"\"\"Returns content of XML fields of a specific name of an element.\n",
    "\n",
    "    Args:\n",
    "        element (lxml.etree._Element): XML element to analyse\n",
    "        field_name (str): name of field to look for\n",
    "\n",
    "    Returns:\n",
    "        list<str>: list of contents found in children of element of given name\n",
    "    \"\"\"\n",
    "    contents = []\n",
    "    for child in list(element):\n",
    "        if field_name in child.tag:\n",
    "            contents.append(child.text)\n",
    "    return contents\n",
    "\n",
    "def get_specific_fields_elements(element, field_name):\n",
    "    \"\"\"Returns XML subelements of the given element with the given name.\n",
    "\n",
    "    Args:\n",
    "        element (lxml.etree._Element): XML element to analyse\n",
    "        field_name (str): name of field to look for\n",
    "\n",
    "    Returns:\n",
    "        list<lxml.etree._Element>: list of children found of the given name\n",
    "    \"\"\"\n",
    "    elements = []\n",
    "    for child in list(element):\n",
    "        if field_name in child.tag:\n",
    "            elements.append(child)\n",
    "    return elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdf_urls(path):\n",
    "    \"\"\"Extracts download URLs of PDFs from XML file.\n",
    "\n",
    "    Args:\n",
    "        path (str): path to XML file\n",
    "\n",
    "    Yields:\n",
    "        str: download URL for PDF\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        tree = etree.parse(f)\n",
    "    root = tree.getroot()\n",
    "    children = list(root)\n",
    "    for c in children:\n",
    "        urls = []\n",
    "        documents_holders = get_specific_fields_elements(c, \"documents\")\n",
    "        for documents_list in documents_holders:\n",
    "            documents = get_specific_fields_elements(documents_list, \"document\")\n",
    "            for document in documents:\n",
    "                files_holders = get_specific_fields_elements(document, \"files\")\n",
    "                for files_list in files_holders:\n",
    "                    files = get_specific_fields_elements(files_list, \"file\")\n",
    "                    for file in files:\n",
    "                        urls += get_specific_fields_content(file, \"url\")\n",
    "        if len(urls) > 0:  # NOTE: can sometimes include jpegs, docx etc.\n",
    "            yield urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for pdf_url in parse_pdf_urls(\"data/export_eprints.soton.ac.uk_2022-.xml\"):\n",
    "    if pdf_url != []:\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from pdfminer.high_level import extract_text_to_fp\n",
    "\n",
    "def check_text_access(pdf_url):\n",
    "    pdf = requests.get(pdf_url)\n",
    "    if pdf.status_code == 200 and \"pdf\" in pdf.headers['content-type']:\n",
    "        out = BytesIO()\n",
    "        try:\n",
    "            extract_text_to_fp(BytesIO(pdf.content), out, output_type=\"text\")\n",
    "            text = out.getvalue().decode(\"utf-8\")\n",
    "            return True\n",
    "        except:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PDF <_io.BytesIO object at 0x10e2dfd80> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for pdf_urls in parse_pdf_urls(\"data/export_eprints.soton.ac.uk_2022-.xml\"):\n",
    "    for pdf_url in pdf_urls:\n",
    "        if check_text_access(pdf_url):\n",
    "            cnt += 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(children[0].keys())\n",
    "print(children[0].get(\"id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in list(children[0]):\n",
    "    local_tag = etree.QName(c.tag).localname\n",
    "    print(local_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_fields_content(element, field_name):\n",
    "    print(\"Contents:\")\n",
    "    print(type(element))\n",
    "    contents = []\n",
    "    for child in list(element):\n",
    "        if field_name in child.tag:\n",
    "            contents.append(child.text)\n",
    "            print(type(child.text))\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_fields_elements(element, field_name):\n",
    "    print(\"Elements:\")\n",
    "    print(type(element))\n",
    "    elements = []\n",
    "    for child in list(element):\n",
    "        if field_name in child.tag:\n",
    "            elements.append(child)\n",
    "            print(type(child))\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_w_download = children[5]\n",
    "documents_holders = get_specific_fields_elements(file_w_download, \"documents\")\n",
    "for documents_list in documents_holders:\n",
    "    documents = get_specific_fields_elements(documents_list, \"document\")\n",
    "    for document in documents:\n",
    "        files_holders = get_specific_fields_elements(document, \"files\")\n",
    "        for files_list in files_holders:\n",
    "            files = get_specific_fields_elements(files_list, \"file\")\n",
    "            for file in files:\n",
    "                print(get_specific_fields_content(file, \"url\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting URLs\n",
    "\n",
    "Good example of PDF with github URL: https://eprints.soton.ac.uk/455168/1/MARINE2021_OC4_TUDelft_WavEC.pdf.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pdfminer.high_level import extract_text_to_fp\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pdf = requests.get(\"https://eprints.soton.ac.uk/455168/1/MARINE2021_OC4_TUDelft_WavEC.pdf.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract text from PDF.\n",
    "\n",
    "**Note:** Might want to `extract_pages` instead, and only check the first page as this is where we would expect the link to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "out = BytesIO()\n",
    "extract_text_to_fp(BytesIO(sample_pdf.content), out, output_type=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = out.getvalue().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(?P<url>https?://(www.)?github.com[^\\s]+)\"\n",
    "result = re.search(pattern, text).group(\"url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"initial text https://www.github.com/abgs some other text http://github.com/username more other text\"\n",
    "matches = re.findall(pattern, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in re.finditer(pattern, \"Just some random text\"):\n",
    "    print(m.group(\"url\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_match = re.search(pattern, sample)\n",
    "print(type(first_match))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broken PDFs and access denied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_access_denied = \"https://eprints.soton.ac.uk/471291/1/2201.09919_1_.pdf\"\n",
    "response_breaks = requests.get(url_access_denied)\n",
    "print(response_breaks.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_ok = requests.get(\"https://eprints.soton.ac.uk/455168/1/MARINE2021_OC4_TUDelft_WavEC.pdf.pdf\")\n",
    "print(response_ok.status_code)\n",
    "print(response_ok.headers['content-length'])\n",
    "print(response_ok.headers['content-type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_eof = \"https://eprints.soton.ac.uk/474475/1/Unconfirmed_794153.crdownload\"\n",
    "response_eof = requests.get(url_eof)\n",
    "print(response_eof.headers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = r\"github.com/[A-Za-z0-9-]+/[A-Za-z_\\-]+\"\n",
    "link = \"https://github.com/stuartemiddleton/uos_clpsych.Table2showstheresultsofourmodelonthevalidationsetusingthestandardevaluationmetrics.7Pleasenotethatthedatasetisimbalancedandthereforeintu-itionsjustdrawnfromonlyaccuracyarenotcorrect.Table2:PerformanceoftheproposedmodelsonTaskAandTaskBusingthevalidationset.MomentsofChangeSuicidalRiskLevelsModelPRF1PRF1Multitask-attn-score0.6740.8000.7240.4150.3970.382Multitask-score0.6800.7600.7130.3550.3310.334Multitask0.5820.7170.6290.3520.3270.335Multitask-attn0.6630.6970.6760.4080.3780.388Here,theprecision,recallandF1scorevaluesob-tainedforeachclass(seeTable5intheappendix)havebeenmacro-averagedbycalculatingthearith-meticmeanofindividualclassesâ€™precision,recallandF1scores.Wehaveusedthemacro-averagingscoretotreatalltheclassesequallyforevaluatingtheoverallperformanceoftheclassifierregard-lessoftheirsupportvalues(i.etheactualoccur-rencesoftheclassinthedataset).Here,weob-servethatMultitask-attn-scoremodelgivesmorepromisingresultsascomparedtootherenlistedmodelsonbothtasks.Thisbehaviourisreflectedintheclassificationresultsontestdatatoo(Table3),whereMultitask-attn-scorehasoutperformedtheremainingfeatureembeddingswiththeBi-LSTMmodelaswellasthebaselinestateoftheartre-sults(Tsakalidisetal.,2022a).FromthemodeloutcomesinTable2and3,onecouldalsoseetheimpactofintroducingattentionlayersintheBi-LSTMmodel.AddingattentionlayersinBi-LSTMmodelhashelpedaccuracyforboththetasks.GiventheclassimbalanceinthedatasetwithmajorityofpostinstancesbelongingtotheNone(0)classandminorityinstancestoEscalation(IE)andSwitch(IS)classes,weseetheperformanceiscom-promisedandbiasedtowardsthemajorityclass,i.e.theclassifierismoresensitivetodetectingthemajorityclass(None(0))patternspreciselybutlesssensitivetodetectingtheminorityclasspatterns{IE,IS}.SeeTable5intheAppendixtoobservetheprecision,recallandF1scoreofthemodelsforeachindividualclassintaskA.Thedatadistri-butionisskewedfortaskBtoo,thusinfluencingitsresultsformajorityandminorityclassesshowninTable6.Overall,onthevalidationset,thepro-posedmodelshaveshownbetterrecallratethanprecision,revealinglowfalsenegativesthanthefalsepositives.Table3andTable4showtheperformanceofourproposedapproachwithvariablefeatureen-codingschemesandattentionlayersinBi-LSTMonthetestsetprovidedbytheCLPsychSharedTask2022.Theentiretrainsetcomprisingof5143\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['github.com/stuartemiddleton/uos_clpsych']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.get(\"https://github.com/fal025/product_hgcn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sw_mentions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f8c870306affaf32e3b88bbbdaf30b4cc7f0b6023c44e1b700a541afb908dd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
